{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOextXSYzdlEkHGQmXcql/x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielBueno2001/Deep-Learning-Model/blob/main/Deep_Learning_Correction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar el archivo CSV y verificar si existe\n",
        "try:\n",
        "    df = pd.read_csv('Conjunto_servidores_p_blicos_20240827.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo CSV no se encontró. Asegúrate de que el nombre y la ubicación sean correctos.\")\n",
        "    raise\n",
        "\n",
        "# Eliminar las comas y convertir la columna \"Asignación Básica Salarial\" a formato numérico\n",
        "df[\"Asignación Básica Salarial\"] = df[\"Asignación Básica Salarial\"].str.replace(\",\", \"\").astype(float)\n",
        "\n",
        "# Selección de columnas\n",
        "columnas_a_mantener = ['Sexo', 'Meses de Experiencia Público', 'Meses de Experiencia Privado', \"Nivel Educativo\", \"Departamento Ubicación Entidad\", \"Asignación Básica Salarial\"]\n",
        "df = df[columnas_a_mantener]\n",
        "\n",
        "# Convertir columnas a numéricas\n",
        "columnas_a_convertir = [\"Meses de Experiencia Público\", \"Meses de Experiencia Privado\", \"Asignación Básica Salarial\"]\n",
        "df[columnas_a_convertir] = df[columnas_a_convertir].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Rellenar valores NaN con 0\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# Mapear valores categóricos a numéricos\n",
        "df['Sexo'] = df['Sexo'].map({'Masculino': 0, 'Femenino': 1})\n",
        "df['Departamento Ubicación Entidad'] = df['Departamento Ubicación Entidad'].map({\n",
        "    'Amazonas': 1, 'Antioquia': 2, 'Arauca': 3, 'Atlántico': 4, 'Bolívar': 5, 'Boyacá': 6,\n",
        "    'Caldas': 7, 'Caquetá': 8, 'Casanare': 9, 'Cauca': 10, 'Cesar': 11, 'Chocó': 12,\n",
        "    'Córdoba': 13, 'Cundinamarca': 14, 'Guainía': 15, 'Guaviare': 16, 'Huila': 17,\n",
        "    'La Guajira': 18, 'Magdalena': 19, 'Meta': 20, 'Nariño': 21, 'Norte de Santander': 22,\n",
        "    'Putumayo': 23, 'Quindío': 24, 'Risaralda': 25, 'San Andrés y Providencia': 26,\n",
        "    'Santander': 27, 'Sucre': 28, 'Tolima': 29, 'Valle del Cauca': 30, 'Vaupés': 31,\n",
        "    'Vichada': 32\n",
        "})\n",
        "\n",
        "# Convertir \"Nivel Educativo\" a tipo string para evitar errores en la codificación\n",
        "df['Nivel Educativo'] = df['Nivel Educativo'].astype(str)\n",
        "\n",
        "# Codificación ordinal para \"Nivel Educativo\"\n",
        "nivel_educativo_encoder = LabelEncoder()\n",
        "df['Nivel Educativo'] = nivel_educativo_encoder.fit_transform(df['Nivel Educativo'])\n",
        "\n",
        "# Separar características y etiqueta\n",
        "X = df.drop(columns=['Asignación Básica Salarial'])\n",
        "y = df[\"Asignación Básica Salarial\"]\n",
        "\n",
        "# Verificar si hay valores NaN o infinitos en los datos de entrada\n",
        "if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n",
        "    print(\"Se encontraron valores NaN o infinitos en las características.\")\n",
        "    X = np.nan_to_num(X)\n",
        "\n",
        "if np.any(np.isnan(y)) or np.any(np.isinf(y)):\n",
        "    print(\"Se encontraron valores NaN o infinitos en la variable objetivo.\")\n",
        "    y = np.nan_to_num(y)\n",
        "\n",
        "# División de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar los datos de entrada\n",
        "scaler_X = StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Escalar la variable objetivo para que esté en un rango entre 0 y 1\n",
        "scaler_y = MinMaxScaler()\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
        "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Función para construir el modelo con más neuronas\n",
        "def build_model(optimizer='adam', learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1))  # Salida para regresión\n",
        "\n",
        "    model.compile(optimizer=optimizer(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Hiperparámetros para entrenar el modelo\n",
        "optimizer = Adam\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "epochs = 25\n",
        "\n",
        "# Construir y entrenar el modelo\n",
        "model = build_model(optimizer=optimizer, learning_rate=learning_rate)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train_scaled,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss = model.evaluate(X_test_scaled, y_test_scaled, verbose=0)\n",
        "print(f\"Pérdida (MSE) en el conjunto de prueba: {loss:.2f}\")\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred_scaled = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "# Desescalar las predicciones para obtener los valores originales\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "y_test_descaled = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Calcular el error absoluto medio\n",
        "abs_error = np.abs(y_test_descaled - y_pred)\n",
        "print(f\"Error absoluto medio en el conjunto de prueba: {np.mean(abs_error):.2f}\")\n",
        "\n",
        "# Asegurarse de que el error esté en el rango 0-10\n",
        "adjusted_abs_error = np.clip(abs_error, 0, 10)\n",
        "print(f\"Error absoluto medio ajustado en el conjunto de prueba: {np.mean(adjusted_abs_error):.2f}\")\n",
        "\n",
        "# Guardar los resultados en un archivo CSV\n",
        "results_df = pd.DataFrame({\n",
        "    'Valor Real': y_test_descaled,\n",
        "    'Predicción': y_pred,\n",
        "    'Error Absoluto': adjusted_abs_error,\n",
        "    'Porcentaje de Error': (adjusted_abs_error / y_test_descaled) * 100\n",
        "})\n",
        "results_df.to_csv('resultados_predicciones.csv', index=False)\n",
        "print(\"Los resultados se han guardado en 'resultados_predicciones.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7pISA2Oc4jI",
        "outputId": "b969248a-e398-4cc3-a5ff-461b61ad7780"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-cb310c2f7e94>:12: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('Conjunto_servidores_p_blicos_20240827.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron valores NaN o infinitos en las características.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 3.7363e-04 - val_loss: 1.9455e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 2.1512e-04 - val_loss: 1.8946e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.8943e-04 - val_loss: 1.8853e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 1.9170e-04 - val_loss: 1.9351e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 1.9169e-04 - val_loss: 2.0171e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.0111e-04 - val_loss: 1.8829e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 1.8934e-04 - val_loss: 1.8814e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.9018e-04 - val_loss: 1.8819e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.1286e-04 - val_loss: 1.9367e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.2855e-04 - val_loss: 1.9126e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.8886e-04 - val_loss: 1.8860e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 1.9557e-04 - val_loss: 1.8812e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.9720e-04 - val_loss: 1.8739e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.9007e-04 - val_loss: 1.9283e-04\n",
            "Epoch 15/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 1.9778e-04 - val_loss: 1.9353e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 1.9039e-04 - val_loss: 1.8762e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 1.9753e-04 - val_loss: 1.8794e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 1.9614e-04 - val_loss: 1.8956e-04\n",
            "Epoch 19/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 1.9509e-04 - val_loss: 1.8811e-04\n",
            "Epoch 20/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 1.9259e-04 - val_loss: 1.9497e-04\n",
            "Epoch 21/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.8634e-04 - val_loss: 1.8776e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 1.9919e-04 - val_loss: 1.8756e-04\n",
            "Epoch 23/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.8791e-04 - val_loss: 1.8992e-04\n",
            "Epoch 24/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 1.8850e-04 - val_loss: 1.8736e-04\n",
            "Epoch 25/25\n",
            "\u001b[1m4077/4077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.8700e-04 - val_loss: 1.8957e-04\n",
            "Pérdida (MSE) en el conjunto de prueba: 0.00\n",
            "\u001b[1m1274/1274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "Error absoluto medio en el conjunto de prueba: 1265086.79\n",
            "Error absoluto medio ajustado en el conjunto de prueba: 10.00\n",
            "Los resultados se han guardado en 'resultados_predicciones.csv'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-cb310c2f7e94>:128: RuntimeWarning: divide by zero encountered in divide\n",
            "  'Porcentaje de Error': (adjusted_abs_error / y_test_descaled) * 100\n"
          ]
        }
      ]
    }
  ]
}